{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"[Solving heterogeneous agent models in discrete time with many idiosyncratic states by perturbation methods](https://cepr.org/active/publications/discussion_papers/dp.php?dpno=13071)\"\n",
    "\n",
    "- <cite data-cite=\"6202365/ECL3ZAR7\"></cite>\n",
    "- Notebook created by Seungcheol Lee from slides by <cite data-cite=\"6202365/ECL3ZAR7\"></cite>\n",
    "- Edits by Chris Carroll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Bayer-Luetticke depart from the Reiter (2009) perturbation method and prodvide an accessible algorithm that can deal with high-dimensional heterogeneity. <cite data-cite=\"6202365/44QWDL5Y\"></cite>\n",
    "\n",
    "The Bayer-Luetticke method has the following broad features:\n",
    "   * Reduces dimensionality after the stationary equilibrium (StE), but before linearization\n",
    "   * Extracts from the StE the important basis functions to represent individual policies (akin to image compression)\n",
    "   * Perturbs only those basis functions but uses the StE as “reference frame” for the policies (akin to video compression)\n",
    "   * Similarly for distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup \n",
    "\n",
    "#### Recursive Dynamic Planning Problem\n",
    "\n",
    "Consider a household problem in presence of aggregate and idiosyncratic risk\n",
    "   * $S_t$ is an (exogenous) aggregate state\n",
    "   * $s_{it}$ is a partly endogenous idiosyncratic state\n",
    "   * $\\mu_t$ is the distribution over s\n",
    "   * Bellman equation:\n",
    "     \\begin{equation}\n",
    "        v(s_{it},S_t,\\mu_t) = \\max\\limits_{x \\in \\Gamma(s_{it},P_t)} u(s_{it},x) + \\beta E v(s_{it+1}(x,s_{it}),S_{t+1},\\mu_{t+1})\n",
    "     \\end{equation}\n",
    "   * Euler equation\n",
    "     \\begin{equation}\n",
    "        u'[x(s_{it},S_t,\\mu_t)] = \\beta R(S_t,\\mu_t) E u'[x(s_{it+1},S_{t+1},\\mu_{t+1})]\n",
    "     \\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No aggregate risk\n",
    "Recall how to solve for a StE\n",
    "   * Discretize the state space (vectorized)\n",
    "   * Optimal policy $h(s_{it};P)$ induces flow utility $\\bar{u}_{\\bar{h}}$ and transition probability matrix $\\Pi_{\\bar{h}}$\n",
    "   * Discretized Bellman equation\n",
    "     \\begin{equation}\n",
    "        \\bar{v} = \\bar{u} + \\beta \\Pi_{\\bar{h}}\\bar{v}\n",
    "      \\end{equation}\n",
    "     holds for optimal policy (assuming a linear interpolant for the continuation value)\n",
    "   * and for the law of motion for the distribution (histograms)     \n",
    "     \\begin{equation}\n",
    "        d\\bar{\\mu} = d\\bar{\\mu} \\Pi_{\\bar{h}}\n",
    "     \\end{equation}\n",
    "     \n",
    "Equilibrium requires    \n",
    "   * $\\bar{h}$ is the optimal policy given P and $v$ (being a linear interpolant)\n",
    "   * $\\bar{v}$ and $d\\bar{\\mu}$ solve the law of motion for the distribution\n",
    "   * Markets clear (some joint requirement on $\\bar{h}$, $\\mu$, and P denoted as $\\Phi(\\bar{h}, \\mu, P) = 0$)\n",
    "\n",
    "This can be solved for efficiently\n",
    "   * Finding $d\\bar{\\mu}$ as the unit-eigenvalue of $\\Pi_{\\bar{h}}$\n",
    "   * Using fast solution techniques for the DP, e.g. EGM\n",
    "   * Using a root-finder to solve for P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Introducing aggregate risk\n",
    "\n",
    "With aggregate risk\n",
    "   * Prices and distribution change over time\n",
    "\n",
    "Yet, for the household:\n",
    "   * Only prices and continuation values matter\n",
    "   * Distribution do not influence the decisions directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefining equilibrium (Reiter, 2002)\n",
    "A sequential equilibrium with recursive individual planning\n",
    "   * A sequence of discretized Bellman equation, such that\n",
    "     \\begin{equation}\n",
    "        v_t = \\bar{u}_{P_t} + \\beta \\Pi_{h_t} v_{t+1}\n",
    "     \\end{equation}\n",
    "     holds for optimal policy $h_t$ (which results from $v_{t+1}$ and $P_t$)\n",
    "   * and a sequence of histogram, such that\n",
    "     \\begin{equation}\n",
    "        d\\mu_{t+1} = d\\mu_t \\Pi_{h_t}\n",
    "     \\end{equation}\n",
    "     holds given the optimal policy\n",
    "   * (Policy functions, $h_t$, that are optimal given $P_t$, $v_{t+1}$)  \n",
    "   * Prices, distribution, and policies lead to market clearing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Change working folder and load Stationary equilibrium (StE)\n",
    "import os\n",
    "import pickle\n",
    "os.chdir('U:\\\\0000_BL_notebook') # select folder where EX3SS_20.p file is in\n",
    "\n",
    "## EX3ss_20.p is the information in the stationary equilibrium (20: the number of illiquid and liquid weath grids )\n",
    "EX3SS=pickle.load(open(\"EX3SS_20.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compact notation (Schmitt-Grohe and Uribe, 2004)\n",
    "The equilibrium conditions as a non-linear difference equation\n",
    "   * Controls: $Y_t = [v_t \\ P_t \\ Z_t^Y]$ and States: $X_t=[\\mu_t \\ S_t \\ Z_t^X]$ where $Z_t$ are purely aggregates states/controls\n",
    "   * Define\n",
    "     \\begin{align}\n",
    "      F(d\\mu_t, S_t, d\\mu_{t+1}, S_{t+1}, v_t, P_t, v_{t+1}, P_{t+1}, \\epsilon_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\mu_{t+1} - d\\mu_t\\Pi_{h_t} \\\\\n",
    "           v_t - (\\bar{u}_{h_t} + \\beta \\Pi_{h_t}v_{t+1}) \\\\\n",
    "           S_{t+1} - H(S_t,d\\mu_t,\\epsilon_{t+1}) \\\\\n",
    "           \\Phi(h_t,d\\mu_t,P_t,S_t) \\\\\n",
    "           \\epsilon_{t+1}\n",
    "           \\end{bmatrix}\n",
    "     \\end{align}\n",
    "     s.t.\n",
    "     \\begin{equation}\n",
    "     h_t(s) = arg \\max\\limits_{x \\in \\Gamma(s,P_t)} u(s,x) + \\beta \\mathop{\\mathbb{E}} v_{t+1}(s')\n",
    "     \\end{equation}\n",
    "   * Function-valued difference equation\n",
    "     $\\mathop{\\mathbb{E}}F(X_t,X_{t+1},Y_t,Y_{t+1},\\epsilon_{t+1}) = 0$\n",
    "   * turns real-valued when we replace the functions by their discretized counterparts\n",
    "   * Standard techniques to solve linearized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, is all solved?\n",
    "The dimensionality of the system F is still an issue\n",
    "   * With high dimensional idiosyncratic states, discretized value functions and distributions become large objects\n",
    "   * For example:\n",
    "     4 income states (grid points) $\\times$ 100 illiquid capital states $\\times$ 100 liquid capital states\n",
    "     $\\Longrightarrow$ $\\geq$ 40,000 control variables in F\n",
    "   * Same number of state variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayer-Luetticke method\n",
    "#### idea\n",
    "1) Apply compression techniques as in video encoding\n",
    "   * Apply a discrete cosine transformation (DCT) to all value/policy function (Chebychev polynomials on roots grid)\n",
    "   * Define a reference \"frame\": the stationary equilibrium (StE)\n",
    "   * Write fluctuations as differences from this reference frame\n",
    "   * Assume all coefficients of the DCT from the StE close to zero do not change after shock\n",
    "   \n",
    "2) Neglect changes in the rank correlation structure of $\\mu$   \n",
    "   * Calculate the Copula, $\\bar{C}$ of $\\mu$ in the StE\n",
    "   * Perturb only the marginal distributions\n",
    "   * Use fixed Copula to calculate an approximate joint distribution from marginals\n",
    "   * Idea follows Krusell and Smith (1998) in that some moments of the distribution do not matter for aggregate dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys \n",
    "sys.path.insert(0,'../')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import matrix_rank\n",
    "import scipy as sc\n",
    "from scipy.stats import norm \n",
    "from scipy.interpolate import interp1d, interp2d, griddata, RegularGridInterpolator, interpn\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool, cpu_count, Process\n",
    "from math import ceil\n",
    "import math as mt\n",
    "from scipy import sparse as sp\n",
    "from scipy import linalg\n",
    "from math import log, cos, pi, sqrt\n",
    "import time\n",
    "from SharedFunc3 import Transition, ExTransitions, GenWeight, MakeGridkm, Tauchen, Fastroot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.io\n",
    "import scipy.fftpack as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details\n",
    "1) Apply compression techniques in video encoding\n",
    "   * Let $\\bar{\\Theta} = dct(\\bar{v})$ be the coefficients obtained from the DCT of the value function in StE\n",
    "   * Define an index set $\\mathop{I}$ that contains the x percent largest (i.e. most important) elements from $\\bar{\\Theta}$\n",
    "   * Let $\\theta$ be a sparse vector with non-zero entries only for elements $i \\in \\mathop{I}$\n",
    "   * Define \n",
    "   \\begin{equation}\n",
    "    \\tilde{\\Theta}(\\theta_t)=\\left\\{\n",
    "      \\begin{array}{@{}ll@{}}\n",
    "         \\bar{\\Theta}(i)+\\theta_t(i), & i \\in \\mathop{I} \\\\\n",
    "         \\bar{\\Theta}(i), & \\text{else}\n",
    "      \\end{array}\\right.\n",
    "   \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## State reduction and Discrete cosine transformation\n",
    "\n",
    "class StateReduc_Dct:\n",
    "    \n",
    "    def __init__(self, par, mpar, grid, Output, targets, Vm, Vk, joint_distr, Copula, c_n_guess, c_a_guess, psi_guess, m_n_star, m_a_star, cap_a_star, mutil_c_n, mutil_c_a,mutil_c, P_H):\n",
    "         \n",
    "        self.par = par\n",
    "        self.mpar = mpar\n",
    "        self.grid = grid\n",
    "        self.Output = Output\n",
    "        self.targets = targets\n",
    "        self.Vm = Vm\n",
    "        self.Vk = Vk\n",
    "        self.joint_distr = joint_distr\n",
    "        self.Copula = Copula\n",
    "        self.mutil_c = mutil_c\n",
    "        self.P_H = P_H\n",
    "        \n",
    "        \n",
    "    def StateReduc(self):\n",
    "        invutil = lambda x : ((1-self.par['xi'])*x)**(1./(1-self.par['xi']))\n",
    "        invmutil = lambda x : (1./x)**(1./self.par['xi'])\n",
    "                       \n",
    "        \n",
    "        Xss=np.asmatrix(np.concatenate((np.sum(np.sum(self.joint_distr.copy(),axis=1),axis =1),  # marginal distribution liquid asset\n",
    "                       np.transpose(np.sum(np.sum(self.joint_distr.copy(),axis=0),axis=1)),  # marginal distribution illiquid asset\n",
    "                       np.sum(np.sum(self.joint_distr.copy(),axis=1),axis=0), # marginal distribution productivity\n",
    "                       [np.log(self.par['RB'])],[ 0.]))).T\n",
    "        \n",
    "        \n",
    "        Yss=np.asmatrix(np.concatenate((invmutil(self.mutil_c.copy().flatten(order = 'F')),invmutil(self.Vk.copy().flatten(order = 'F')),\n",
    "                      [np.log(self.par['Q'])],[ np.log(self.par['PI'])],[np.log(self.Output)],\n",
    "                      [np.log(self.par['G'])],[np.log(self.par['W'])],[np.log(self.par['R'])],[np.log(self.par['PROFITS'])],\n",
    "                      [np.log(self.par['N'])],[np.log(self.targets['T'])],[np.log(self.grid['K'])],\n",
    "                      [np.log(self.targets['B'])]))).T\n",
    "        \n",
    "        # Mapping for Histogram\n",
    "\n",
    "        Gamma_state = np.zeros((self.mpar['nm']+self.mpar['nk']+self.mpar['nh'], self.mpar['nm']+self.mpar['nk']+self.mpar['nh'] - 4))\n",
    "        for j in range(self.mpar['nm']-1):\n",
    "            Gamma_state[0:self.mpar['nm'],j] = -np.squeeze(Xss[0:self.mpar['nm']])\n",
    "            Gamma_state[j,j]=1. - Xss[j]\n",
    "            Gamma_state[j,j]=Gamma_state[j,j] - np.sum(Gamma_state[0:self.mpar['nm'],j])\n",
    "        bb = self.mpar['nm']\n",
    "\n",
    "        for j in range(self.mpar['nk']-1):\n",
    "            Gamma_state[bb+np.arange(0,self.mpar['nk'],1), bb+j-1] = -np.squeeze(Xss[bb+np.arange(0,self.mpar['nk'],1)])\n",
    "            Gamma_state[bb+j,bb-1+j] = 1. - Xss[bb+j]\n",
    "            Gamma_state[bb+j,bb-1+j] = Gamma_state[bb+j,bb-1+j] - np.sum(Gamma_state[bb+np.arange(0,self.mpar['nk']),bb-1+j])\n",
    "        bb = self.mpar['nm'] + self.mpar['nk']\n",
    "\n",
    "        for j in range(self.mpar['nh']-2):\n",
    "            Gamma_state[bb+np.arange(0,self.mpar['nh']-1,1), bb+j-2] = -np.squeeze(Xss[bb+np.arange(0,self.mpar['nh']-1,1)])\n",
    "            Gamma_state[bb+j,bb-2+j] = 1. - Xss[bb+j]\n",
    "            Gamma_state[bb+j,bb-2+j] = Gamma_state[bb+j,bb-2+j] - np.sum(Gamma_state[bb+np.arange(0,self.mpar['nh']-1,1),bb-2+j])\n",
    "\n",
    "\n",
    "        self.mpar['os'] = len(Xss) - (self.mpar['nm']+self.mpar['nk']+self.mpar['nh'])\n",
    "        self.mpar['oc'] = len(Yss) - 2*(self.mpar['nm']*self.mpar['nk']*self.mpar['nh'])\n",
    "        \n",
    "        aggrshock = self.par['aggrshock']\n",
    "        accuracy = self.par['accuracy']\n",
    "       \n",
    "        indexMUdct = self.do_dct(invmutil(self.mutil_c.copy().flatten(order='F')),self.mpar,accuracy)\n",
    "               \n",
    "        indexVKdct = self.do_dct(invmutil(self.Vk.copy()),self.mpar,accuracy)\n",
    "                \n",
    "        aux = np.shape(Gamma_state)\n",
    "        self.mpar['numstates'] = np.int64(aux[1] + self.mpar['os'])\n",
    "        self.mpar['numcontrols'] = np.int64(len(indexMUdct) + len(indexVKdct) + self.mpar['oc'])\n",
    "        \n",
    "        State = np.zeros((self.mpar['numstates'],1))\n",
    "        State_m = State\n",
    "        Contr = np.zeros((self.mpar['numcontrols'],1))\n",
    "        Contr_m = Contr\n",
    "        \n",
    "        return {'Xss': Xss, 'Yss':Yss, 'Gamma_state': Gamma_state, \n",
    "                'par':self.par, 'mpar':self.mpar, 'aggrshock':aggrshock,\n",
    "                'Copula':self.Copula,'grid':self.grid,'targets':self.targets,'P_H':self.P_H, \n",
    "                'joint_distr': self.joint_distr, 'Output': self.Output, 'indexMUdct':indexMUdct, 'indexVKdct':indexVKdct,\n",
    "                'State':State, 'State_m':State_m, 'Contr':Contr, 'Contr_m':Contr_m}\n",
    "\n",
    "    def do_dct(self, obj, mpar, level):\n",
    "\n",
    "        obj = np.reshape(obj.copy(),(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "        X1 = sf.dct(obj,norm='ortho',axis=0)\n",
    "        X2 = sf.dct(X1.copy(),norm='ortho',axis=1)\n",
    "        X3 = sf.dct(X2.copy(),norm='ortho',axis=2)\n",
    "\n",
    "        \n",
    "        XX = X3.flatten(order='F')\n",
    "        ind = np.argsort(abs(XX.copy()))[::-1]\n",
    "        i = 1   \n",
    "        while linalg.norm(XX[ind[:i]].copy())/linalg.norm(XX) < level:\n",
    "              i += 1    \n",
    "        \n",
    "        needed = i\n",
    "        \n",
    "        index_reduced = np.sort(ind[:i])\n",
    "        \n",
    "        \n",
    "        return index_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Decoding\n",
    "   * Now we reconstruct $v_t=v(\\theta_t)=idct(\\tilde{\\Theta}(\\theta_i))$\n",
    "   * This means that in the StE the reduction step adds no addtional approximation error as $v(0)=\\bar{v}$ by construction\n",
    "   * Yet, it allows to reduce the number of derivatives that need to be calculated from the outset.\n",
    "   \n",
    "3) Analogously for the histogram\n",
    "   * $\\mu_t$ as $\\bar{C}(\\bar{\\mu_t}^1,...,\\bar{\\mu_t}^n)$ for n being the dimensionality of the idiosyncratic states\n",
    "   * The StE distribution is obtained when $\\mu = \\bar{C}(\\bar{\\mu}^1,...,\\bar{\\mu}^n)$\n",
    "   * Typically prices are only influenced through the marginal distributions\n",
    "   * The approach ensures that changes in the mass of one, say wealth, state are distributed in a sensible way across the other dimension\n",
    "   * The implied distributions look \"similar\" to the StE one (different in (Reiter, 2009))\n",
    "\n",
    "4) Too many equations\n",
    "   * The system\n",
    "     \\begin{align}\n",
    "      F(\\{d\\mu_t^1,...,d\\mu_t^n\\}, S_t, \\{d\\mu_{t+1}^1,...,d\\mu_{t+1}^n\\}, S_{t+1}, \\theta_t, P_t, \\theta_{t+1}, P_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n) - d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n)\\Pi_{h_t} \\\\\n",
    "           dct[idct(\\tilde{\\Theta(\\theta_t)}) - (\\bar{u}_{h_t} + \\beta \\Pi_{h_t}idct(\\tilde{\\Theta(\\theta_{t+1})}] \\\\\n",
    "           S_{t+1} - H(S_t,d\\mu_t) \\\\\n",
    "           \\Phi(h_t,d\\mu_t,P_t,S_t) \\\\\n",
    "           \\end{bmatrix}\n",
    "     \\end{align}\n",
    "     has too many equations\n",
    "   * Use only difference in marginals and the differences on $\\mathop{I}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "## Construct the system of equations (including decoding): The system in 4)\n",
    "def Fsys(State, Stateminus, Control_sparse, Controlminus_sparse, StateSS, ControlSS, \n",
    "         Gamma_state, indexMUdct, indexVKdct, par, mpar, grid, targets, Copula, P, aggrshock):\n",
    "    \n",
    "    '''\n",
    "    System of equations written in Schmitt-GrohÃ©-Uribe generic form with states and controls\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "   \n",
    "    State : ndarray\n",
    "        Vector of state variables t+1 (only marginal distributions for histogram)\n",
    "    Stateminus: ndarray\n",
    "        Vector of state variables t (only marginal distributions for histogram)\n",
    "    Control_sparse: ndarray\n",
    "        Vector of state variables t+1 (only coefficients of sparse polynomial)\n",
    "    Controlminus_sparse: ndarray\n",
    "        Vector of state variables t (only coefficients of sparse polynomial)\n",
    "    StateSS and ControlSS: matrix or ndarray\n",
    "        Value of the state and control variables in steady state. For the Value functions these are at full grids.\n",
    "    Gamma_state: coo_matrix\n",
    "        Mapping such that perturbationof marginals are still distributions (sum to 1).\n",
    "    Gamma_control: ndarray\n",
    "        Values of the polynomial base at all nodes to map sparse coefficient changes to full grid\n",
    "    InvGamma: coo_matrix\n",
    "        Projection of Value functions etc. to Coeffeicent space for sparse polynomials.\n",
    "    par, moar: dict\n",
    "        Model and numerical parameters (structure)\n",
    "    Grid: dict\n",
    "        Liquid, illiquid and productivity grid\n",
    "    Targets: dict\n",
    "        Stores targets for government policy\n",
    "   Copula : dict\n",
    "        points for interpolation of joint distribution\n",
    "    P: ndarray\n",
    "        steady state transition matrix\n",
    "    aggrshock: str \n",
    "        sets wether the Aggregate shock is TFP or uncertainty\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## Initialization\n",
    "    mutil = lambda x : 1./np.power(x,par['xi'])\n",
    "#    invmutil = lambda x : (1./x)**(1./par['xi'])\n",
    "    invmutil = lambda x : np.power(1./x,1./par['xi'])\n",
    "    \n",
    "    # Generate meshes for b,k,h\n",
    "\n",
    "    \n",
    "    # number of states, controls\n",
    "    nx = mpar['numstates'] # number of states\n",
    "    ny = mpar['numcontrols'] # number of controls\n",
    "    NxNx= nx - mpar['os'] # number of states w/o aggregates\n",
    "    Ny = len(indexMUdct) + len(indexVKdct)\n",
    "    NN = mpar['nm']*mpar['nh']*mpar['nk'] # number of points in the full grid\n",
    "    \n",
    "    # Initialize LHS and RHS\n",
    "    LHS = np.zeros((nx+Ny+mpar['oc'],1))\n",
    "    RHS = np.zeros((nx+Ny+mpar['oc'],1))\n",
    "    \n",
    "    ## Indexes for LHS/RHS\n",
    "    # Indexes for controls\n",
    "    mutil_cind = np.array(range(len(indexMUdct)))\n",
    "    Vkind = len(indexMUdct) + np.array(range(len(indexVKdct)))\n",
    "    \n",
    "    Qind = Ny\n",
    "    PIind = Ny+1\n",
    "    Yind = Ny+2\n",
    "    Gind = Ny+3\n",
    "    Wind = Ny+4\n",
    "    Rind = Ny+5\n",
    "    Profitind = Ny+6\n",
    "    Nind = Ny+7\n",
    "    Tind = Ny+8\n",
    "    Kind = Ny+9\n",
    "    Bind = Ny+10\n",
    "    \n",
    "    # Indexes for states\n",
    "    #distr_ind = np.arange(mpar['nm']*mpar['nh']-mpar['nh']-1)\n",
    "    marginal_mind = range(mpar['nm']-1)\n",
    "    marginal_kind = range(mpar['nm']-1,mpar['nm']+mpar['nk']-2)\n",
    "    marginal_hind = range(mpar['nm']+mpar['nk']-2,mpar['nm']+mpar['nk']+mpar['nh']-4)\n",
    "    \n",
    "    RBind = NxNx\n",
    "    Sind = NxNx+1\n",
    "    \n",
    "    ## Control variables\n",
    "    \n",
    "    Control = Control_sparse.copy()\n",
    "    Controlminus = Controlminus_sparse.copy()\n",
    "           \n",
    "    Control[-mpar['oc']:] = ControlSS[-mpar['oc']:].copy() + Control_sparse[-mpar['oc']:,:].copy()\n",
    "    Controlminus[-mpar['oc']:] = ControlSS[-mpar['oc']:].copy() + Controlminus_sparse[-mpar['oc']:,:].copy()\n",
    "    \n",
    "    ## State variables\n",
    "    # read out marginal histogram in t+1, t\n",
    "    Distribution = StateSS[:-2].copy() + Gamma_state.copy().dot(State[:NxNx].copy())\n",
    "    Distributionminus = StateSS[:-2].copy() + Gamma_state.copy().dot(Stateminus[:NxNx].copy())\n",
    "\n",
    "    # Aggregate Endogenous States\n",
    "    RB = StateSS[-2] + State[-2]\n",
    "    RBminus = StateSS[-2] + Stateminus[-2]\n",
    "    \n",
    "    # Aggregate Exogenous States\n",
    "    S = StateSS[-1] + State[-1]\n",
    "    Sminus = StateSS[-1] + Stateminus[-1]\n",
    "    \n",
    "    ## Split the control vector into items with names\n",
    "    # Controls\n",
    "\n",
    "    XX = np.zeros((NN,1))\n",
    "    XX[indexMUdct] = Control[mutil_cind]\n",
    "    \n",
    "    aux = np.reshape(XX,(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=0)\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=1)\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=2)\n",
    "    \n",
    "    mutil_c_dev = aux.copy()\n",
    "    \n",
    "    mutil_c = mutil(mutil_c_dev.copy().flatten(order='F') + np.squeeze(np.asarray(ControlSS[np.array(range(NN))])))\n",
    "    \n",
    "    XX = np.zeros((NN,1))\n",
    "    XX[indexVKdct] = Control[Vkind]\n",
    "    \n",
    "    aux = np.reshape(XX,(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=0)\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=1)\n",
    "    aux = sf.idct(aux.copy(),norm='ortho',axis=2)\n",
    "    \n",
    "\n",
    "    Vk_dev = aux.copy()\n",
    "    Vk = mutil(Vk_dev.copy().flatten(order='F')+np.squeeze(np.asarray(ControlSS[np.array(range(NN))+NN])))\n",
    "    \n",
    "    \n",
    "    # Aggregate Controls (t+1)\n",
    "    PI = np.exp(Control[PIind])\n",
    "    Y = np.exp(Control[Yind])\n",
    "    K = np.exp(Control[Kind])\n",
    "    B = np.exp(Control[Bind])\n",
    "    \n",
    "    # Aggregate Controls (t)\n",
    "    PIminus = np.exp(Controlminus[PIind])\n",
    "    Qminus = np.exp(Controlminus[Qind])\n",
    "    Yminus = np.exp(Controlminus[Yind])\n",
    "    Gminus = np.exp(Controlminus[Gind])\n",
    "    Wminus = np.exp(Controlminus[Wind])\n",
    "    Rminus = np.exp(Controlminus[Rind])\n",
    "    Profitminus = np.exp(Controlminus[Profitind])\n",
    "    Nminus = np.exp(Controlminus[Nind])\n",
    "    Tminus = np.exp(Controlminus[Tind])\n",
    "    Kminus = np.exp(Controlminus[Kind])\n",
    "    Bminus = np.exp(Controlminus[Bind])\n",
    "    \n",
    "    \n",
    "    ## Write LHS values\n",
    "    # Controls\n",
    "    LHS[nx+Vkind] = Controlminus[Vkind]\n",
    "    LHS[nx+mutil_cind] = Controlminus[mutil_cind]\n",
    "    LHS[nx+Qind] = Qminus\n",
    "    LHS[nx+Yind] = Yminus\n",
    "    LHS[nx+Gind] = Gminus\n",
    "    LHS[nx+Wind] = Wminus\n",
    "    LHS[nx+Rind] = Rminus\n",
    "    LHS[nx+Profitind] = Profitminus\n",
    "    LHS[nx+Nind] = Nminus\n",
    "    LHS[nx+Tind] = Tminus\n",
    "    LHS[nx+Kind] = Kminus\n",
    "    LHS[nx+Bind] = Bminus\n",
    "    \n",
    "    \n",
    "    # States\n",
    "    # Marginal Distributions (Marginal histograms)\n",
    "    #LHS[distr_ind] = Distribution[:mpar['nm']*mpar['nh']-1-mpar['nh']].copy()\n",
    "    LHS[marginal_mind] = Distribution[:mpar['nm']-1]\n",
    "    LHS[marginal_kind] = Distribution[mpar['nm']:mpar['nm']+mpar['nk']-1]\n",
    "    LHS[marginal_hind] = Distribution[mpar['nm']+mpar['nk']:mpar['nm']+mpar['nk']+mpar['nh']-2]\n",
    "    \n",
    "    LHS[RBind] = RB\n",
    "    LHS[Sind] = S\n",
    "    \n",
    "    # take into account that RB is in logs\n",
    "    RB = np.exp(RB.copy())\n",
    "    RBminus = np.exp(RBminus) \n",
    "    \n",
    "    ## Set of differences for exogenous process\n",
    "    RHS[Sind] = par['rhoS']*Sminus\n",
    "    \n",
    "    if aggrshock == 'MP':\n",
    "        EPS_TAYLOR = Sminus\n",
    "        TFP = 1.0\n",
    "    elif aggrshock == 'TFP':\n",
    "        TFP = np.exp(Sminus)\n",
    "        EPS_TAYLOR = 0\n",
    "    elif aggrshock == 'Uncertainty':\n",
    "        TFP = 1.0\n",
    "        EPS_TAYLOR = 0\n",
    "   \n",
    "        #Tauchen style for probability distribution next period\n",
    "        P = ExTransitions(np.exp(Sminus), grid, mpar, par)['P_H']\n",
    "        \n",
    "    \n",
    "    marginal_mminus = np.transpose(Distributionminus[:mpar['nm']].copy())\n",
    "    marginal_kminus = np.transpose(Distributionminus[mpar['nm']:mpar['nm']+mpar['nk']].copy())\n",
    "    marginal_hminus = np.transpose(Distributionminus[mpar['nm']+mpar['nk']:mpar['nm']+mpar['nk']+mpar['nh']].copy())\n",
    "    \n",
    "    Hminus = np.sum(np.multiply(grid['h'][:-1],marginal_hminus[:,:-1]))\n",
    "    Lminus = np.sum(np.multiply(grid['m'],marginal_mminus))\n",
    "    \n",
    "    RHS[nx+Bind] = Lminus\n",
    "    RHS[nx+Kind] = np.sum(grid['k']*np.asarray(marginal_kminus))\n",
    "    \n",
    "    # Calculate joint distributions\n",
    "    cumdist = np.zeros((mpar['nm']+1,mpar['nk']+1,mpar['nh']+1))\n",
    "    cm,ck,ch = np.meshgrid(np.asarray(np.cumsum(marginal_mminus)), np.asarray(np.cumsum(marginal_kminus)), np.asarray(np.cumsum(marginal_hminus)), indexing = 'ij')\n",
    "    \n",
    "    # griddata does not support extrapolation for 3D\n",
    "    #cumdist[1:,1:,1:] = np.reshape(Copula((cm.flatten(order='F').copy(),ck.flatten(order='F').copy(),ch.flatten(order='F').copy())),(mpar['nm'],mpar['nk'],mpar['nh']), order='F')\n",
    "    Copula_aux = griddata(Copula['grid'],Copula['value'],(cm.flatten(order='F').copy(),ck.flatten(order='F').copy(),ch.flatten(order='F').copy()))\n",
    "    Copula_bounds = griddata(Copula['grid'],Copula['value'],(cm.flatten(order='F').copy(),ck.flatten(order='F').copy(),ch.flatten(order='F').copy()),method='nearest')\n",
    "    Copula_aux[np.isnan(Copula_aux.copy())] = Copula_bounds[np.isnan(Copula_aux.copy())].copy()\n",
    "    \n",
    "    cumdist[1:,1:,1:] = np.reshape(Copula_aux,(mpar['nm'],mpar['nk'],mpar['nh']), order='F')\n",
    "    JDminus = np.diff(np.diff(np.diff(cumdist,axis=0),axis=1),axis=2)\n",
    "    \n",
    "    meshes={}\n",
    "    meshes['m'], meshes['k'], meshes['h'] = np.meshgrid(grid['m'],grid['k'],grid['h'], indexing = 'ij')\n",
    "    \n",
    "    ## Aggregate Output\n",
    "    mc = par['mu'] - (par['beta']* np.log(PI)*Y/Yminus - np.log(PIminus))/par['kappa']\n",
    "    \n",
    "    RHS[nx+Nind] = np.power(par['tau']*TFP*par['alpha']*np.power(Kminus,(1.-par['alpha']))*mc,1./(1.-par['alpha']+par['gamma']))\n",
    "    RHS[nx+Yind] = (TFP*np.power(Nminus,par['alpha'])*np.power(Kminus,1.-par['alpha']))\n",
    "    ## Prices that are not a part of control vector\n",
    "    # Wage Rate\n",
    "    RHS[nx+Wind] = TFP * par['alpha'] * mc *np.power((Kminus/Nminus),1.-par['alpha'])\n",
    "    # Return on Capital\n",
    "    RHS[nx+Rind] = TFP * (1.-par['alpha']) * mc *np.power((Nminus/Kminus),par['alpha']) - par['delta']\n",
    "    # Profits for Enterpreneurs\n",
    "    RHS[nx+Profitind] = (1.-mc)*Yminus - Yminus*(1./(1.-par['mu']))/par['kappa']/2.*np.log(PIminus)**2 + 1./2.*par['phi']*((K-Kminus)**2)/Kminus\n",
    "    \n",
    "       \n",
    "    ## Wages net of leisure services\n",
    "    WW = (par['gamma']/(1.+par['gamma'])*(Nminus/Hminus)*Wminus).item()*np.ones((mpar['nm'],mpar['nk'],mpar['nh']))\n",
    "    WW[:,:,-1] = Profitminus.item()*par['profitshare']*np.ones((mpar['nm'],mpar['nk']))\n",
    "    \n",
    "    ## Incomes (grids)\n",
    "    inc ={}\n",
    "    inc['labor'] = par['tau']*WW.copy()*meshes['h'].copy()\n",
    "    inc['rent'] = meshes['k']*Rminus.item()\n",
    "    inc['capital'] = meshes['k']*Qminus.item()\n",
    "    inc['money'] = meshes['m'].copy()*(RBminus.item()/PIminus.item()+(meshes['m']<0)*par['borrwedge']/PIminus.item())\n",
    "    \n",
    "    \n",
    "    ## Update policies\n",
    "    EVk = np.reshape(np.asarray(np.reshape(Vk.copy(),(mpar['nm']*mpar['nk'], mpar['nh']),order = 'F').dot(P.copy().T)),(mpar['nm'],mpar['nk'],mpar['nh']),order = 'F')\n",
    "    RBaux = (RB.item()+(meshes['m']<0).copy()*par['borrwedge'])/PI.item()\n",
    "    EVm = np.reshape(np.asarray(np.reshape(np.multiply(RBaux.flatten(order='F').T.copy(),mutil_c.flatten(order='F').copy()),(mpar['nm']*mpar['nk'],mpar['nh']),order='F').dot(np.transpose(P.copy()))),(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    \n",
    "    \n",
    "    result_EGM_policyupdate = EGM_policyupdate(EVm,EVk,Qminus.item(),PIminus.item(),RBminus.item(),inc,meshes,grid,par,mpar)\n",
    "    c_a_star = result_EGM_policyupdate['c_a_star']\n",
    "    m_a_star = result_EGM_policyupdate['m_a_star']\n",
    "    k_a_star = result_EGM_policyupdate['k_a_star']\n",
    "    c_n_star = result_EGM_policyupdate['c_n_star']\n",
    "    m_n_star = result_EGM_policyupdate['m_n_star']\n",
    "    \n",
    "    meshaux = meshes.copy()\n",
    "    meshaux['h'][:,:,-1] = 1000.\n",
    "    \n",
    "    ## Update Marginal Value of Bonds\n",
    "    mutil_c_n = mutil(c_n_star.copy())\n",
    "    mutil_c_a = mutil(c_a_star.copy())\n",
    "    mutil_c_aux = par['nu']*mutil_c_a + (1-par['nu'])*mutil_c_n\n",
    "    aux = invmutil(mutil_c_aux.copy().flatten(order='F'))-np.squeeze(np.asarray(ControlSS[np.array(range(NN))]))\n",
    "    aux = np.reshape(aux,(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=0)\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=1)\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=2)\n",
    "\n",
    "    \n",
    "    DC = np.asmatrix(aux.copy().flatten(order='F')).T\n",
    "    \n",
    "    RHS[nx+mutil_cind] = DC[indexMUdct]\n",
    "    \n",
    "    \n",
    "    ## Update Marginal Value of capital\n",
    "    EVk = np.reshape(Vk,(mpar['nm']*mpar['nk'],mpar['nh']),order='F').dot(P.copy().T)\n",
    "            \n",
    "    Vpoints = np.concatenate(( [meshaux['m'].flatten(order='F')],[meshaux['k'].flatten(order='F')],[meshaux['h'].flatten(order='F')]),axis=0).T\n",
    "    # griddata does not support extrapolation for 3D   \n",
    "    Vk_next = griddata(Vpoints,np.asarray(EVk).flatten(order='F').copy(),(m_n_star.copy().flatten(order='F'),meshaux['k'].copy().flatten(order='F'),meshaux['h'].copy().flatten(order='F')),method='linear')\n",
    "    Vk_next_bounds = griddata(Vpoints,np.asarray(EVk).flatten(order='F').copy(),(m_n_star.copy().flatten(order='F'),meshaux['k'].copy().flatten(order='F'),meshaux['h'].copy().flatten(order='F')),method='nearest')\n",
    "    Vk_next[np.isnan(Vk_next.copy())] = Vk_next_bounds[np.isnan(Vk_next.copy())].copy()\n",
    "       \n",
    "    Vk_aux = par['nu']*(Rminus.item()+Qminus.item())*mutil_c_a + (1-par['nu'])*Rminus.item()*mutil_c_n +par['beta']*(1-par['nu'])*np.reshape(Vk_next,(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    \n",
    "    aux = invmutil(Vk_aux.copy().flatten(order='F')) - np.squeeze(np.asarray(ControlSS[np.array(range(NN))+NN]))\n",
    "    aux = np.reshape(aux.copy(),(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=0)\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=1)\n",
    "    aux = sf.dct(aux.copy(),norm='ortho',axis=2)    \n",
    "    \n",
    "    \n",
    "    DC = np.asmatrix(aux.copy().flatten(order='F')).T\n",
    "        \n",
    "    RHS[nx+Vkind] = DC[indexVKdct]\n",
    "    \n",
    "    ## Differences for distriutions\n",
    "    # find next smallest on-grid value for money choices\n",
    "    weight11 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    weight12 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    weight21 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    weight22 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    \n",
    "    weightn1 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    weightn2 = np.empty((mpar['nm']*mpar['nk'],mpar['nh'],mpar['nh']))\n",
    "    \n",
    "    ra_genweight = GenWeight(m_a_star,grid['m'])\n",
    "    Dist_m_a = ra_genweight['weight'].copy()\n",
    "    idm_a = ra_genweight['index'].copy()\n",
    "    \n",
    "    rn_genweight = GenWeight(m_n_star,grid['m'])\n",
    "    Dist_m_n = rn_genweight['weight'].copy()\n",
    "    idm_n = rn_genweight['index'].copy()\n",
    "    \n",
    "    rk_genweight = GenWeight(k_a_star,grid['k'])\n",
    "    Dist_k = rk_genweight['weight'].copy()\n",
    "    idk_a = rk_genweight['index'].copy()\n",
    "    \n",
    "    idk_n = np.reshape(np.tile(np.outer(np.ones((mpar['nm'])),np.array(range(mpar['nk']))),(1,1,mpar['nh'])),(mpar['nm'],mpar['nk'],mpar['nh']),order = 'F')\n",
    "        \n",
    "    # Transition matrix for adjustment case\n",
    "    idm_a = np.tile(np.asmatrix(idm_a.copy().flatten('F')).T,(1,mpar['nh']))\n",
    "    idk_a = np.tile(np.asmatrix(idk_a.copy().flatten('F')).T,(1,mpar['nh']))\n",
    "    idh = np.kron(np.array(range(mpar['nh'])),np.ones((1,mpar['nm']*mpar['nk']*mpar['nh'])))\n",
    "    \n",
    "    idm_a = idm_a.copy().astype(int)\n",
    "    idk_a = idk_a.copy().astype(int)\n",
    "    idh = idh.copy().astype(int)\n",
    "    \n",
    "    index11 = np.ravel_multi_index([idm_a.flatten(order='F'),idk_a.flatten(order='F'),idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    index12 = np.ravel_multi_index([idm_a.flatten(order='F'),idk_a.flatten(order='F')+1,idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    index21 = np.ravel_multi_index([idm_a.flatten(order='F')+1,idk_a.flatten(order='F'),idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    index22 = np.ravel_multi_index([idm_a.flatten(order='F')+1,idk_a.flatten(order='F')+1,idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    # for no-adjustment case\n",
    "    idm_n = np.tile(np.asmatrix(idm_n.copy().flatten('F')).T,(1,mpar['nh']))\n",
    "    idk_n = np.tile(np.asmatrix(idk_n.copy().flatten('F')).T,(1,mpar['nh']))\n",
    "        \n",
    "    idm_n = idm_n.copy().astype(int)\n",
    "    idk_n = idk_n.copy().astype(int)\n",
    "    \n",
    "    indexn1 = np.ravel_multi_index([idm_n.flatten(order='F'),idk_n.flatten(order='F'),idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    indexn2 = np.ravel_multi_index([idm_n.flatten(order='F')+1,idk_n.flatten(order='F'),idh.flatten(order='F')],\n",
    "                                       (mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    \n",
    "    for hh in range(mpar['nh']):\n",
    "        \n",
    "        # corresponding weights\n",
    "        weight11_aux = (1-Dist_m_a[:,:,hh].copy())*(1-Dist_k[:,:,hh].copy())\n",
    "        weight12_aux = (1-Dist_m_a[:,:,hh].copy())*(Dist_k[:,:,hh].copy())  \n",
    "        weight21_aux = Dist_m_a[:,:,hh].copy()*(1-Dist_k[:,:,hh].copy())\n",
    "        weight22_aux = Dist_m_a[:,:,hh].copy()*(Dist_k[:,:,hh].copy())\n",
    "        \n",
    "        weightn1_aux = (1-Dist_m_n[:,:,hh].copy())\n",
    "        weightn2_aux = (Dist_m_n[:,:,hh].copy())\n",
    "        \n",
    "        # dimensions (m*k,h',h)\n",
    "        weight11[:,:,hh] = np.outer(weight11_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        weight12[:,:,hh] = np.outer(weight12_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        weight21[:,:,hh] = np.outer(weight21_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        weight22[:,:,hh] = np.outer(weight22_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        \n",
    "        weightn1[:,:,hh] = np.outer(weightn1_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        weightn2[:,:,hh] = np.outer(weightn2_aux.flatten(order='F').copy(),P[hh,:].copy())\n",
    "        \n",
    "    weight11= np.ndarray.transpose(weight11.copy(),(0,2,1))       \n",
    "    weight12= np.ndarray.transpose(weight12.copy(),(0,2,1))       \n",
    "    weight21= np.ndarray.transpose(weight21.copy(),(0,2,1))       \n",
    "    weight22= np.ndarray.transpose(weight22.copy(),(0,2,1))       \n",
    "    \n",
    "    rowindex = np.tile(range(mpar['nm']*mpar['nk']*mpar['nh']),(1,4*mpar['nh']))\n",
    "    \n",
    "    H_a = sp.coo_matrix((np.hstack((weight11.flatten(order='F'),weight21.flatten(order='F'),weight12.flatten(order='F'),weight22.flatten(order='F'))), \n",
    "                   (np.squeeze(rowindex), np.hstack((np.squeeze(np.asarray(index11)),np.squeeze(np.asarray(index21)),np.squeeze(np.asarray(index12)),np.squeeze(np.asarray(index22)))) )), \n",
    "                    shape=(mpar['nm']*mpar['nk']*mpar['nh'],mpar['nm']*mpar['nk']*mpar['nh']) )\n",
    "\n",
    "    weightn1= np.ndarray.transpose(weightn1.copy(),(0,2,1))       \n",
    "    weightn2= np.ndarray.transpose(weightn2.copy(),(0,2,1))       \n",
    "    \n",
    "    rowindex = np.tile(range(mpar['nm']*mpar['nk']*mpar['nh']),(1,2*mpar['nh']))\n",
    "    \n",
    "    H_n = sp.coo_matrix((np.hstack((weightn1.flatten(order='F'),weightn2.flatten(order='F'))), \n",
    "                   (np.squeeze(rowindex), np.hstack((np.squeeze(np.asarray(indexn1)),np.squeeze(np.asarray(indexn2)))) )), \n",
    "                    shape=(mpar['nm']*mpar['nk']*mpar['nh'],mpar['nm']*mpar['nk']*mpar['nh']) )\n",
    "    \n",
    "    # Joint transition matrix and transitions\n",
    "    H = par['nu']*H_a.copy() +(1-par['nu'])*H_n.copy()    \n",
    "        \n",
    "    JD_new = JDminus.flatten(order='F').copy().dot(H.todense())\n",
    "    JD_new = np.reshape(np.asarray(JD_new.copy()),(mpar['nm'],mpar['nk'],mpar['nh']),order='F')\n",
    "    \n",
    "    # Next period marginal histograms\n",
    "    # liquid assets\n",
    "    aux_m = np.sum(np.sum(JD_new.copy(),axis=1),axis=1)\n",
    "    RHS[marginal_mind] = np.asmatrix(aux_m[:-1].copy()).T\n",
    "    \n",
    "    # illiquid asset\n",
    "    aux_k = np.sum(np.sum(JD_new.copy(),axis=0),axis=1)\n",
    "    RHS[marginal_kind] = np.asmatrix(aux_k[:-1].copy()).T\n",
    "    \n",
    "    # human capital\n",
    "    aux_h = np.sum(np.sum(JD_new.copy(),axis=0),axis=0)\n",
    "    RHS[marginal_hind] = np.asmatrix(aux_h[:-2].copy()).T\n",
    "    \n",
    "    ## Third Set: Government Budget constraint\n",
    "    # Return on bonds (Taylor Rule)\n",
    "    RHS[RBind] = np.log(par['RB'])+par['rho_R']*np.log(RBminus/par['RB']) + np.log(PIminus/par['PI'])*((1.-par['rho_R'])*par['theta_pi'])+EPS_TAYLOR\n",
    "    \n",
    "    # Inflation jumps to equilibrate real bond supply and demand\n",
    "    \n",
    "    if par['tau'] < 1:\n",
    "       \n",
    "       taxrevenue = (1-par['tau'])*Wminus*Nminus + (1-par['tau'])*Profitminus\n",
    "       RHS[nx+PIind] = par['rho_B']*np.log(Bminus/targets['B'])+par['rho_B']*np.log(RBminus/par['RB']) - (par['rho_B']+par['gamma_pi'])*np.log(PIminus/par['PI']) - par['gamma_T'] *np.log(Tminus/targets['T'])\n",
    "                       \n",
    "       LHS[nx+PIind] = np.log(B/targets['B'])\n",
    "       \n",
    "       # Government expenditure\n",
    "       RHS[nx+Gind] = B - Bminus*RBminus/PIminus +Tminus\n",
    "       RHS[nx+Tind] = taxrevenue\n",
    "       \n",
    "       # Resulting price of capital\n",
    "       RHS[nx+Qind] = (par['phi']*(K/Kminus-1)+1) - par['ABS']\n",
    "       \n",
    "    else:\n",
    "       RHS[nx+PIind] = targets['B']\n",
    "       LHS[nx+PIind] = B\n",
    "       \n",
    "       RHS[nx+Gind] = targets['G'] \n",
    "       RHS[nx+Tind] = 0.\n",
    "    \n",
    "       RHS[nx+Qind] = (par['phi']*(K/Kminus-1)+1) - par['ABS']\n",
    "       \n",
    "    ## Difference\n",
    "    Difference = (LHS-RHS)\n",
    "    \n",
    "          \n",
    "    \n",
    "    return {'Difference':Difference, 'LHS':LHS, 'RHS':RHS, 'JD_new': JD_new, 'c_a_star':c_a_star, 'm_a_star':m_a_star,\n",
    "            'k_a_star':k_a_star,'c_n_star':c_n_star,'m_n_star':m_n_star,'P':P}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Update policy in transition (found in Fsys)\n",
    "\n",
    "def EGM_policyupdate(EVm,EVk, Qminus, PIminus, RBminus, inc, meshes,grid,par,mpar):\n",
    "    \n",
    "    ## EGM step 1\n",
    "    EMU = par['beta']*np.reshape(EVm.copy(),(mpar['nm'],mpar['nk'],mpar['nh']), order = 'F')\n",
    "    c_new = 1./np.power(EMU,(1./par['xi']))\n",
    "    # Calculate assets consistent with choices being (m')\n",
    "    # Calculate initial money position from the budget constraint,\n",
    "    # that leads to the optimal consumption choice\n",
    "    m_star_n = (c_new.copy() + meshes['m'].copy()-inc['labor'].copy()-inc['rent'].copy())\n",
    "    m_star_n = m_star_n.copy()/(RBminus/PIminus+(m_star_n.copy()<0)*par['borrwedge']/PIminus)\n",
    "    \n",
    "    # Identify binding constraints\n",
    "    binding_constraints = meshes['m'].copy() < np.tile(m_star_n[0,:,:].copy(),(mpar['nm'],1,1))\n",
    "    \n",
    "    # Consumption when drawing assets m' to zero: Eat all resources\n",
    "    Resource = inc['labor'].copy() + inc['rent'].copy() + inc['money'].copy()\n",
    "    \n",
    "    m_star_n = np.reshape(m_star_n.copy(),(mpar['nm'],mpar['nk']*mpar['nh']),order='F')\n",
    "    c_n_aux = np.reshape(c_new.copy(),(mpar['nm'],mpar['nk']*mpar['nh']),order='F')\n",
    "    \n",
    "    # Interpolate grid['m'] and c_n_aux defined on m_n_aux over grid['m']\n",
    "    # Check monotonicity of m_n_aux\n",
    "    if np.sum(np.abs(np.diff(np.sign(np.diff(m_star_n.copy(),axis=0)),axis=0)),axis=1).max() != 0.:\n",
    "       print(' Warning: non monotone future liquid asset choice encountered ')\n",
    "       \n",
    "    c_update = np.zeros((mpar['nm'],mpar['nk']*mpar['nh']))\n",
    "    m_update = np.zeros((mpar['nm'],mpar['nk']*mpar['nh']))\n",
    "    \n",
    "    for hh in range(mpar['nk']*mpar['nh']):\n",
    "         \n",
    "        Savings = interp1d(np.squeeze(np.asarray(m_star_n[:,hh].copy())), grid['m'].copy(), fill_value='extrapolate')\n",
    "        m_update[:,hh] = Savings(grid['m'].copy())\n",
    "        Consumption = interp1d(np.squeeze(np.asarray(m_star_n[:,hh].copy())), np.squeeze(np.asarray(c_n_aux[:,hh].copy())), fill_value='extrapolate')\n",
    "        c_update[:,hh] = Consumption(grid['m'].copy())\n",
    "    \n",
    "    \n",
    "    c_n_star = np.reshape(c_update,(mpar['nm'],mpar['nk'],mpar['nh']),order = 'F')\n",
    "    m_n_star = np.reshape(m_update,(mpar['nm'],mpar['nk'],mpar['nh']),order = 'F')\n",
    "    \n",
    "    c_n_star[binding_constraints] = np.squeeze(np.asarray(Resource[binding_constraints].copy() - grid['m'][0]))\n",
    "    m_n_star[binding_constraints] = grid['m'].copy().min()\n",
    "    \n",
    "    m_n_star[m_n_star>grid['m'][-1]] = grid['m'][-1]\n",
    "    \n",
    "    ## EGM step 2: find Optimal Portfolio Combinations\n",
    "    term1 = par['beta']*np.reshape(EVk,(mpar['nm'],mpar['nk'],mpar['nh']),order = 'F')\n",
    "    \n",
    "    E_return_diff = term1/Qminus - EMU\n",
    "    \n",
    "    # Check quasi-monotonicity of E_return_diff\n",
    "    if np.sum(np.abs(np.diff(np.sign(E_return_diff),axis=0)),axis = 0).max() > 2.:\n",
    "       print(' Warning: multiple roots of portfolio choic encountered')\n",
    "       \n",
    "    # Find an m_a for given ' taht solves the difference equation\n",
    "    m_a_aux = Fastroot(grid['m'],E_return_diff)\n",
    "    m_a_aux = np.maximum(m_a_aux.copy(),grid['m'][0])\n",
    "    m_a_aux = np.minimum(m_a_aux.copy(),grid['m'][-1])\n",
    "    m_a_aux = np.reshape(m_a_aux.copy(),(mpar['nk'],mpar['nh']),order = 'F')\n",
    "    \n",
    "    ## EGM step 3\n",
    "    # Constraints for money and capital are not binding\n",
    "    EMU = np.reshape(EMU.copy(),(mpar['nm'],mpar['nk']*mpar['nh']),order = 'F')\n",
    "\n",
    "    # Interpolation of psi-function at m*_n(m,k)\n",
    "    idx = np.digitize(m_a_aux, grid['m'])-1 # find indexes on grid next smallest to optimal policy\n",
    "    idx[m_a_aux<=grid['m'][0]]   = 0  # if below minimum\n",
    "    idx[m_a_aux>=grid['m'][-1]] = mpar['nm']-2 #if above maximum\n",
    "    step = np.diff(grid['m'].copy()) # Stepsize on grid\n",
    "    s = (m_a_aux.copy() - grid['m'][idx])/step[idx]  # Distance of optimal policy to next grid point\n",
    "\n",
    "    aux_index = np.array(range(0,(mpar['nk']*mpar['nh'])))*mpar['nm']  # aux for linear indexes\n",
    "    aux3      = EMU.flatten(order = 'F').copy()[idx.flatten(order='F').copy()+aux_index.flatten(order = 'F').copy()]  # calculate linear indexes\n",
    "\n",
    "    # Interpolate EMU(m',k',s'*h',M',K') over m*_n(k'), m-dim is dropped\n",
    "    EMU_star        = aux3 + s.flatten(order = 'F')*(EMU.flatten(order='F').copy()[idx.flatten(order = 'F').copy() + aux_index.flatten(order = 'F').copy()+1]-aux3) # linear interpolation\n",
    "\n",
    "    c_a_aux         = 1/(EMU_star.copy()**(1/par['xi']))\n",
    "    cap_expenditure = np.squeeze(inc['capital'][0,:,:])\n",
    "    auxL            = np.squeeze(inc['labor'][0,:,:])\n",
    "\n",
    "    # Resources that lead to capital choice k' = c + m*(k') + k' - w*h*N = value of todays cap and money holdings\n",
    "    Resource = c_a_aux.copy() + m_a_aux.flatten(order = 'F').copy() + cap_expenditure.flatten(order = 'F').copy() - auxL.flatten(order = 'F').copy()\n",
    "\n",
    "    c_a_aux  = np.reshape(c_a_aux.copy(), (mpar['nk'], mpar['nh']),order = 'F')\n",
    "    Resource = np.reshape(Resource.copy(), (mpar['nk'], mpar['nh']),order = 'F')\n",
    "\n",
    "    # Money constraint is not binding, but capital constraint is binding\n",
    "    m_star_zero = np.squeeze(m_a_aux[0,:].copy()) # Money holdings that correspond to k'=0:  m*(k=0)\n",
    "\n",
    "    # Use consumption at k'=0 from constrained problem, when m' is on grid\n",
    "    aux_c     = np.reshape(c_new[:,0,:],(mpar['nm'], mpar['nh']),order = 'F')\n",
    "    aux_inc   = np.reshape(inc['labor'][0,0,:],(1, mpar['nh']),order = 'F')\n",
    "    cons_list = []\n",
    "    res_list  = []\n",
    "    mon_list  = []\n",
    "    cap_list  = []\n",
    "\n",
    "\n",
    "    for j in range(mpar['nh']):\n",
    "      # When choosing zero capital holdings, HHs might still want to choose money holdings smaller than m*(k'=0)\n",
    "       if m_star_zero[j]>grid['m'][0]:\n",
    "        # Calculate consumption policies, when HHs chooses money holdings lower than m*(k'=0) and capital holdings k'=0 and save them in cons_list\n",
    "        log_index    = grid['m'].T.copy() < m_star_zero[j]\n",
    "        # aux_c is the consumption policy under no cap. adj.\n",
    "        c_k_cons     = aux_c[log_index, j].copy()\n",
    "        cons_list.append( c_k_cons.copy() ) # Consumption at k'=0, m'<m_a*(0)\n",
    "        # Required Resources: Money choice + Consumption - labor income Resources that lead to k'=0 and m'<m*(k'=0)\n",
    "        res_list.append( grid['m'].T[log_index] + c_k_cons.copy() - aux_inc[0,j] )\n",
    "        mon_list.append( grid['m'].T[log_index])\n",
    "        cap_list.append( np.zeros((np.sum(log_index))))\n",
    "    \n",
    "\n",
    "    # Merge lists\n",
    "    c_a_aux  = np.reshape(c_a_aux.copy(),(mpar['nk'], mpar['nh']),order = 'F')\n",
    "    m_a_aux  = np.reshape(m_a_aux.copy(),(mpar['nk'], mpar['nh']),order = 'F')\n",
    "    Resource = np.reshape(Resource.copy(),(mpar['nk'], mpar['nh']),order = 'F')\n",
    "    \n",
    "    cons_list_1=[]\n",
    "    res_list_1=[]\n",
    "    mon_list_1=[]\n",
    "    cap_list_1=[]\n",
    "    \n",
    "    for j in range(mpar['nh']):\n",
    "   \n",
    "      cons_list_1.append( np.vstack((np.asmatrix(cons_list[j]).T, np.asmatrix(c_a_aux[:,j]).T)) )\n",
    "      res_list_1.append( np.vstack((np.asmatrix(res_list[j]).T, np.asmatrix(Resource[:,j]).T)) )\n",
    "      mon_list_1.append( np.vstack((np.asmatrix(mon_list[j]).T, np.asmatrix(m_a_aux[:,j]).T)) )\n",
    "      cap_list_1.append( np.vstack((np.asmatrix(cap_list[j].copy()).T, np.asmatrix(grid['k']).T)) )\n",
    "    \n",
    "    ## EGM step 4: Interpolate back to fixed grid\n",
    "    c_a_star = np.zeros((mpar['nm']*mpar['nk'], mpar['nh']),order = 'F')\n",
    "    m_a_star = np.zeros((mpar['nm']*mpar['nk'], mpar['nh']),order = 'F')\n",
    "    k_a_star = np.zeros((mpar['nm']*mpar['nk'], mpar['nh']),order = 'F')\n",
    "    Resource_grid  = np.reshape(inc['capital']+inc['money']+inc['rent'],(mpar['nm']*mpar['nk'], mpar['nh']),order = 'F')\n",
    "    labor_inc_grid = np.reshape(inc['labor'],(mpar['nm']*mpar['nk'], mpar['nh']),order = 'F')\n",
    "\n",
    "    for j in range(mpar['nh']):\n",
    "      log_index=Resource_grid[:,j] < res_list[j][0]\n",
    "    \n",
    "      # when at most one constraint binds:\n",
    "      # Check monotonicity of resources\n",
    "      \n",
    "      if np.sum(np.abs(np.diff(np.sign(np.diff(res_list[j])))),axis = 0).max() != 0. :\n",
    "         print('warning(non monotone resource list encountered)')\n",
    "      cons = interp1d(np.squeeze(np.asarray(res_list_1[j].copy())), np.squeeze(np.asarray(cons_list_1[j].copy())),fill_value='extrapolate')\n",
    "      c_a_star[:,j] = cons(Resource_grid[:,j].copy())\n",
    "      mon = interp1d(np.squeeze(np.asarray(res_list_1[j].copy())), np.squeeze(np.asarray(mon_list_1[j].copy())),fill_value='extrapolate')\n",
    "      m_a_star[:,j] = mon(Resource_grid[:,j].copy())\n",
    "      cap = interp1d(np.squeeze(np.asarray(res_list_1[j].copy())), np.squeeze(np.asarray(cap_list_1[j].copy())),fill_value='extrapolate')\n",
    "      k_a_star[:,j] = cap(Resource_grid[:,j].copy())\n",
    "      # Lowest value of res_list corresponds to m_a'=0 and k_a'=0.\n",
    "    \n",
    "      # Any resources on grid smaller then res_list imply that HHs consume all resources plus income.\n",
    "      # When both constraints are binding:\n",
    "      c_a_star[log_index,j] = Resource_grid[log_index,j].copy() + labor_inc_grid[log_index,j].copy()-grid['m'][0]\n",
    "      m_a_star[log_index,j] = grid['m'][0]\n",
    "      k_a_star[log_index,j] = 0.\n",
    "\n",
    "\n",
    "    c_a_star = np.reshape(c_a_star.copy(),(mpar['nm'] ,mpar['nk'], mpar['nh']),order = 'F')\n",
    "    k_a_star = np.reshape(k_a_star.copy(),(mpar['nm'] ,mpar['nk'], mpar['nh']),order = 'F')\n",
    "    m_a_star = np.reshape(m_a_star.copy(),(mpar['nm'] ,mpar['nk'], mpar['nh']),order = 'F')\n",
    "\n",
    "    k_a_star[k_a_star.copy()>grid['k'][-1]] = grid['k'][-1]\n",
    "    m_a_star[m_a_star.copy()>grid['m'][-1]] = grid['m'][-1]    \n",
    "    \n",
    "    return {'c_a_star': c_a_star, 'm_a_star': m_a_star, 'k_a_star': k_a_star,'c_n_star': c_n_star, 'm_n_star': m_n_star}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Choose an aggregate shock to perturb(one of three shocks: MP, TFP, Uncertainty)\n",
    "\n",
    "EX3SS['par']['aggrshock']           = 'MP'\n",
    "EX3SS['par']['rhoS']    = 0.0      # Persistence of variance\n",
    "EX3SS['par']['sigmaS']  = 0.001    # STD of variance shocks\n",
    "\n",
    "#EX3SS['par']['aggrshock']           = 'TFP'\n",
    "#EX3SS['par']['rhoS']    = 0.95\n",
    "#EX3SS['par']['sigmaS']  = 0.0075\n",
    "    \n",
    "#EX3SS['par']['aggrshock']           = 'Uncertainty'\n",
    "#EX3SS['par']['rhoS']    = 0.84    # Persistence of variance\n",
    "#EX3SS['par']['sigmaS']  = 0.54    # STD of variance shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Choose an accuracy of approximation with DCT\n",
    "EX3SS['par']['accuracy'] = 0.99999 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Implement state reduction and DCT\n",
    "EX3SR=StateReduc_Dct(**EX3SS)\n",
    "SR=EX3SR.StateReduc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## plot Impurse Response Functions\n",
    "\n",
    "def plot_IRF(mpar,par,gx,hx,joint_distr,Gamma_state,grid,targets,Output):\n",
    "        \n",
    "    x0 = np.zeros((mpar['numstates'],1))\n",
    "    x0[-1] = par['sigmaS']\n",
    "        \n",
    "    MX = np.vstack((np.eye(len(x0)), gx))\n",
    "    IRF_state_sparse=[]\n",
    "    x=x0.copy()\n",
    "    mpar['maxlag']=16\n",
    "        \n",
    "    for t in range(0,mpar['maxlag']):\n",
    "        IRF_state_sparse.append(np.dot(MX,x))\n",
    "        x=np.dot(hx,x)\n",
    "        \n",
    "    IRF_state_sparse = np.asmatrix(np.squeeze(np.asarray(IRF_state_sparse))).T\n",
    "        \n",
    "    aux = np.sum(np.sum(joint_distr,1),0)\n",
    "        \n",
    "    scale={}\n",
    "    scale['h'] = np.tile(np.vstack((1,aux[-1])),(1,mpar['maxlag']))\n",
    "        \n",
    "    IRF_distr = Gamma_state*IRF_state_sparse[:mpar['numstates']-mpar['os'],:mpar['maxlag']]\n",
    "        \n",
    "    # preparation\n",
    "        \n",
    "    IRF_H = 100*grid['h'][:-1]*IRF_distr[mpar['nm']+mpar['nk']:mpar['nm']+mpar['nk']+mpar['nh']-1,1:]/par['H']\n",
    "    K = np.asarray(grid['k']*IRF_distr[mpar['nm']:mpar['nm']+mpar['nk'],:] + grid['K']).T\n",
    "    I = (K[1:] - (1-par['delta'])*K[:-1]).T\n",
    "    IRF_I = 100*(I/(par['delta']*grid['K'])-1)\n",
    "    IRF_K = 100*grid['k']*IRF_distr[mpar['nm']:mpar['nm']+mpar['nk'],1:]/grid['K']\n",
    "    IRF_M = 100*grid['m']*IRF_distr[:mpar['nm'],1:]/(targets['B']+par['ABS']*grid['K'])\n",
    "    K=K.copy().T\n",
    "    M = grid['m']*IRF_distr[:mpar['nm'],:] + targets['B'] - par['ABS']*(K-grid['K'])\n",
    "    IRF_S=100*IRF_state_sparse[mpar['numstates']-1,:-1]\n",
    "    \n",
    "    Y = Output*(1+IRF_state_sparse[-1-mpar['oc']+3, :-1])\n",
    "    G = par['G']*(1+IRF_state_sparse[-1-mpar['oc']+4, :-1])\n",
    "    IRF_C = 100*((Y-G-I)/(Output-par['G']-par['delta']*grid['K'])-1)\n",
    "    IRF_Y=100*IRF_state_sparse[-1-mpar['oc']+3, :-1]\n",
    "    IRF_G=100*IRF_state_sparse[-1-mpar['oc']+4, :-1]\n",
    "    IRF_W=100*IRF_state_sparse[-1-mpar['oc']+5, :-1]\n",
    "    IRF_N=100*IRF_state_sparse[-1-mpar['oc']+8, :-1]\n",
    "    IRF_R=100*IRF_state_sparse[-1-mpar['oc']+6, :-1]\n",
    "    IRF_PI=100*100*IRF_state_sparse[-1-mpar['oc']+2, :-1]\n",
    "        \n",
    "    PI=1 + IRF_state_sparse[-1-mpar['oc']+2, :-1]\n",
    "    Q = par['Q']*(1+IRF_state_sparse[-1-mpar['oc']+1, :-1])\n",
    "    R = par['R']*(1+IRF_state_sparse[-1-mpar['oc']+6, :-1])\n",
    "    RB=par['RB']+(IRF_state_sparse[-2, 1:])\n",
    "    IRF_RB=100*100*(RB-par['RB'])\n",
    "    IRF_RBREAL=100*100*(RB/PI-par['RB'])\n",
    "    IRF_Q = 100*100*(Q-par['Q'])\n",
    "    IRF_D = 100*100*((1+IRF_R/100)*par['R'] - par['R'])\n",
    "    Deficit = 100*(M[:,1:] - M[:,:-1]/PI)/Y\n",
    "    IRF_LP = 100*100*(((Q[:,1:]+R[:,1:])/Q[:,:-1]-RB[:,:-1]/PI[:,1:])-((1+par['R']/par['Q'])-par['RB']))\n",
    "    \n",
    "    \n",
    "    f_Y = plt.figure(1)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_Y)),label='IRF_Y')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "#    patch_Y = mpatches.Patch(color='blue', label='IRF_Y_thetapi')\n",
    "#    plt.legend(handles=[patch_Y])\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_Y.show()\n",
    "#        \n",
    "    f_C = plt.figure(2)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_C)),label='IRF_C')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_C.show()\n",
    "\n",
    "    f_I = plt.figure(3)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_I)),label='IRF_I')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_I.show()\n",
    "        \n",
    "    f_G = plt.figure(4)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_G)), label='IRF_G')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    # plt.ylim((-1, 1))\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_G.show()\n",
    "\n",
    "    f_Deficit = plt.figure(5)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(Deficit)), label='IRF_Deficit')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percentage Points') \n",
    "    f_Deficit.show()\n",
    "\n",
    "    f_K = plt.figure(6)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_K)), label='IRF_K')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_K.show()\n",
    "\n",
    "    f_M = plt.figure(7)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_M)), label='IRF_M')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_M.show()\n",
    "\n",
    "    f_H = plt.figure(8)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_H)), label='IRF_H')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_H.show()\n",
    "        \n",
    "    f_S = plt.figure(10)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_S)), label='IRF_S')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_S.show()        \n",
    "        \n",
    "    f_RBPI = plt.figure(11)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_RB)), label='nominal', color='red', linestyle='--')\n",
    "    line2,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_RBREAL)), label='real', color='blue')\n",
    "    plt.legend(handles=[line1, line2])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_RBPI.show()\n",
    "\n",
    "    f_RB = plt.figure(12)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_RB)), label='IRF_RB')\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_RB.show()\n",
    "        \n",
    "    f_PI = plt.figure(13)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_PI)), label='IRF_PI')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_PI.show()\n",
    "\n",
    "    f_Q = plt.figure(14)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_Q)), label='IRF_Q')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_Q.show()\n",
    "\n",
    "    f_D = plt.figure(15)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_D)), label='IRF_D')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_D.show()\n",
    "\n",
    "    f_LP = plt.figure(16)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']-1),np.squeeze(np.asarray(IRF_LP)), label='IRF_LP')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Basis Points') \n",
    "    f_LP.show()\n",
    "\n",
    "    f_N = plt.figure(17)\n",
    "    line1,=plt.plot(range(1,mpar['maxlag']),np.squeeze(np.asarray(IRF_N)), label='IRF_N')\n",
    "    plt.legend(handles=[line1])\n",
    "    plt.plot(range(0,mpar['maxlag']),np.zeros((mpar['maxlag'])),'k--' )\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Percent') \n",
    "    f_N.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "## Obtain numerical derivatives (F1~F4) using Fsys and calculate linear policy or transition functions by SGU (04) \n",
    "\n",
    "def SGU_solver(Xss,Yss,Gamma_state,indexMUdct,indexVKdct,par,mpar,grid,targets,Copula,P_H,aggrshock): #\n",
    "\n",
    "    State       = np.zeros((mpar['numstates'],1))\n",
    "    State_m     = State.copy()\n",
    "    Contr       = np.zeros((mpar['numcontrols'],1))\n",
    "    Contr_m     = Contr.copy()\n",
    "        \n",
    "\n",
    "    F = lambda S, S_m, C, C_m : Fsys(S, S_m, C, C_m,\n",
    "                                         Xss,Yss,Gamma_state,indexMUdct,indexVKdct,\n",
    "                                         par,mpar,grid,targets,Copula,P_H,aggrshock)\n",
    "        \n",
    "      \n",
    "    start_time = time.clock() \n",
    "    result_F = F(State,State_m,Contr.copy(),Contr_m.copy())\n",
    "    end_time   = time.clock()\n",
    "    print ('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "    Fb=result_F['Difference'].copy()\n",
    "        \n",
    "    pool=cpu_count()/2\n",
    "\n",
    "    F1=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numstates']))\n",
    "    F2=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numcontrols']))\n",
    "    F3=np.zeros((mpar['numstates'] + mpar['numcontrols'], mpar['numstates']))\n",
    "    F4=np.asmatrix(np.vstack((np.zeros((mpar['numstates'], mpar['numcontrols'])), np.eye(mpar['numcontrols'],mpar['numcontrols']) )))\n",
    "        \n",
    "    print ('Use Schmitt Grohe Uribe Algorithm')\n",
    "    print (' A *E[xprime uprime] =B*[x u]')\n",
    "    print (' A = (dF/dxprimek dF/duprime), B =-(dF/dx dF/du)')\n",
    "        \n",
    "    #numscale=1\n",
    "    pnum=pool\n",
    "    packagesize=int(ceil(mpar['numstates'] / float(3*pnum)))\n",
    "    blocks=int(ceil(mpar['numstates'] / float(packagesize) ))\n",
    "\n",
    "    par['scaleval1'] = 1e-5\n",
    "    par['scaleval2'] = 1e-5\n",
    "        \n",
    "    start_time = time.clock()\n",
    "    print ('Computing Jacobian F1=DF/DXprime F3 =DF/DX')\n",
    "    print ('Total number of parallel blocks: ', str(blocks), '.')\n",
    "        \n",
    "    FF1=[]\n",
    "    FF3=[]\n",
    "        \n",
    "    for bl in range(0,blocks):\n",
    "        range_= range(bl*packagesize, min(packagesize*(bl+1),mpar['numstates']))\n",
    "        DF1=np.asmatrix( np.zeros((len(Fb),len(range_))) )\n",
    "        DF3=np.asmatrix( np.zeros((len(Fb),len(range_))) )\n",
    "        cc=np.zeros((mpar['numcontrols'],1))\n",
    "        ss=np.zeros((mpar['numstates'],1))\n",
    "        for Xct in range_:\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval1']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss.copy(),X,cc.copy(),cc.copy())\n",
    "            DF3[:, Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss.copy(),cc.copy(),cc.copy())\n",
    "            DF1[:, Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        if sum(range_ == mpar['numstates'] - 2) == 1:\n",
    "            Xct=mpar['numstates'] - 2\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval2']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss.copy(),X,cc.copy(),cc.copy())\n",
    "            DF3[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss.copy(),cc.copy(),cc.copy())\n",
    "            DF1[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        if sum(range_ == mpar['numstates'] - 1) == 1:\n",
    "            Xct=mpar['numstates'] - 1\n",
    "            X=np.zeros((mpar['numstates'],1))\n",
    "            h=par['scaleval2']\n",
    "            X[Xct]=h\n",
    "            Fx=F(ss.copy(),X,cc.copy(),cc.copy())\n",
    "            DF3[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "            Fx=F(X,ss.copy(),cc.copy(),cc.copy())\n",
    "            DF1[:,Xct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        FF1.append(DF1.copy())\n",
    "        FF3.append(DF3.copy())\n",
    "        print ('Block number: ', str(bl),' done.')\n",
    "\n",
    "    for i in range(0,int(ceil(mpar['numstates'] / float(packagesize)) )):\n",
    "        range_= range(i*packagesize, min(packagesize*(i+1),mpar['numstates']))\n",
    "        F1[:,range_]=FF1[i]\n",
    "        F3[:,range_]=FF3[i]\n",
    "\n",
    "    end_time   = time.clock()\n",
    "    print ('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "\n",
    "    # jacobian wrt Y'\n",
    "    packagesize=int(ceil(mpar['numcontrols'] / (3.0*pnum)))\n",
    "    blocks=int(ceil(mpar['numcontrols'] / float(packagesize)))\n",
    "    print ('Computing Jacobian F2 - DF/DYprime')\n",
    "    print ('Total number of parallel blocks: ', str(blocks),'.')\n",
    "\n",
    "    FF=[]\n",
    "        \n",
    "    start_time = time.clock()\n",
    "        \n",
    "    for bl in range(0,blocks):\n",
    "        range_= range(bl*packagesize,min(packagesize*(bl+1),mpar['numcontrols']))\n",
    "        DF2=np.asmatrix(np.zeros((len(Fb),len(range_))))\n",
    "        cc=np.zeros((mpar['numcontrols'],1))\n",
    "        ss=np.zeros((mpar['numstates'],1))\n",
    "        for Yct in range_:\n",
    "            Y=np.zeros((mpar['numcontrols'],1))\n",
    "            h=par['scaleval2']\n",
    "            Y[Yct]=h\n",
    "            Fx=F(ss.copy(),ss.copy(),Y,cc.copy())\n",
    "            DF2[:,Yct - bl*packagesize]=(Fx['Difference'] - Fb) / h\n",
    "        FF.append(DF2.copy())\n",
    "        print ('Block number: ',str(bl),' done.')\n",
    "\n",
    "        \n",
    "    for i in range(0,int(ceil(mpar['numcontrols'] / float(packagesize) ))):\n",
    "        range_=range(i*packagesize, min(packagesize*(i+1),mpar['numcontrols']))\n",
    "        F2[:,range_]=FF[i]\n",
    "        \n",
    "    end_time = time.clock()\n",
    "    print ('Elapsed time is ', (end_time-start_time), ' seconds.')\n",
    "        \n",
    "        \n",
    "    FF=[]\n",
    "    FF1=[]\n",
    "    FF3=[]\n",
    "        \n",
    "    cc=np.zeros((mpar['numcontrols'],1))\n",
    "    ss=np.zeros((mpar['numstates'],1))\n",
    "    \n",
    "    for Yct in range(0, mpar['oc']):\n",
    "        Y=np.zeros((mpar['numcontrols'],1))\n",
    "        h=par['scaleval2']\n",
    "        Y[-1-Yct]=h\n",
    "        Fx=F(ss.copy(),ss.copy(),cc.copy(),Y)\n",
    "        F4[:,-1 - Yct]=(Fx['Difference'] - Fb) / h\n",
    "        \n",
    "    F2[mpar['nm']+mpar['nk']-3:mpar['numstates']-2,:] = 0\n",
    "    \n",
    "    s,t,Q,Z=linalg.qz(np.hstack((F1,F2)), -np.hstack((F3,F4)), output='complex')\n",
    "    abst = abs(np.diag(t))*(abs(np.diag(t))!=0.)+  (abs(np.diag(t))==0.)*10**(-11)\n",
    "    #relev=np.divide(abs(np.diag(s)), abs(np.diag(t)))\n",
    "    relev=np.divide(abs(np.diag(s)), abst)    \n",
    "    \n",
    "    ll=sorted(relev)\n",
    "    slt=relev >= 1\n",
    "    nk=sum(slt)\n",
    "    slt=1*slt\n",
    "    \n",
    "\n",
    "    s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort='ouc', output='complex')\n",
    "    \n",
    "    def sortOverridEigen(x, y):\n",
    "        out = np.empty_like(x, dtype=bool)\n",
    "        xzero = (x == 0)\n",
    "        yzero = (y == 0)\n",
    "        out[xzero & yzero] = False\n",
    "        out[~xzero & yzero] = True\n",
    "        out[~yzero] = (abs(x[~yzero]/y[~yzero]) > ll[-1 - mpar['numstates']])\n",
    "        return out        \n",
    "    \n",
    "    if nk > mpar['numstates']:\n",
    "       if mpar['overrideEigen']:\n",
    "          print ('Warning: The Equilibrium is Locally Indeterminate, critical eigenvalue shifted to: ', str(ll[-1 - mpar['numstates']]))\n",
    "          slt=relev > ll[-1 - mpar['numstates']]\n",
    "          nk=sum(slt)\n",
    "          s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort=sortOverridEigen, output='complex')\n",
    "          \n",
    "       else:\n",
    "          print ('No Local Equilibrium Exists, last eigenvalue: ', str(ll[-1 - mpar['numstates']]))\n",
    "        \n",
    "    elif nk < mpar['numstates']:\n",
    "       if mpar['overrideEigen']:\n",
    "          print ('Warning: No Local Equilibrium Exists, critical eigenvalue shifted to: ', str(ll[-1 - mpar['numstates']]))\n",
    "          slt=relev > ll[-1 - mpar['numstates']]\n",
    "          nk=sum(slt)\n",
    "          s_ord,t_ord,__,__,__,Z_ord=linalg.ordqz(np.hstack((F1,F2)), -np.hstack((F3,F4)), sort=sortOverridEigen, output='complex')\n",
    "          \n",
    "       else:\n",
    "          print ('No Local Equilibrium Exists, last eigenvalue: ', str(ll[-1 - mpar['numstates']]))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    z21=Z_ord[nk:,0:nk]\n",
    "    z11=Z_ord[0:nk,0:nk]\n",
    "    s11=s_ord[0:nk,0:nk]\n",
    "    t11=t_ord[0:nk,0:nk]\n",
    "    \n",
    "    if matrix_rank(z11) < nk:\n",
    "       print ('Warning: invertibility condition violated')   \n",
    "\n",
    "    z11i  = np.dot(np.linalg.inv(z11), np.eye(nk)) # compute the solution\n",
    "\n",
    "    gx = np.real(np.dot(z21,z11i))\n",
    "    hx = np.real(np.dot(z11,np.dot(np.dot(np.linalg.inv(s11),t11),z11i)))\n",
    "         \n",
    "    return{'hx': hx, 'gx': gx, 'F1': F1, 'F2': F2, 'F3': F3, 'F4': F4, 'par': par }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Run SGU_solver and check running time\n",
    "\n",
    "start_time0 = time.clock()\n",
    "print('SGU_solver')\n",
    "SGUresult=SGU_solver(SR['Xss'],SR['Yss'],SR['Gamma_state'],SR['indexMUdct'],SR['indexVKdct'],SR['par'],SR['mpar'],SR['grid'],SR['targets'],SR['Copula'],SR['P_H'],SR['aggrshock'])\n",
    "print('plot_IRF')\n",
    "plot_IRF(SR['mpar'],SR['par'],SGUresult['gx'],SGUresult['hx'],SR['joint_distr'],SR['Gamma_state'],SR['grid'],SR['targets'],SR['Output'])\n",
    "end_time0 = time.clock()\n",
    "print('Elapsed time is ',  (end_time0-start_time0), ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6202365/44QWDL5Y": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "6202365/44QWDL5Y",
     "issue": "3",
     "issued": {
      "month": 3,
      "year": 2009
     },
     "note": "Citation Key: reiterSolving",
     "page": "649-665",
     "page-first": "649",
     "title": "Solving heterogeneous-agent models by projection and perturbation",
     "type": "article-journal",
     "volume": "33"
    },
    "6202365/ECL3ZAR7": {
     "author": [
      {
       "family": "Bayer",
       "given": "Christian"
      },
      {
       "family": "Luetticke",
       "given": "Ralph"
      }
     ],
     "id": "6202365/ECL3ZAR7",
     "issued": {
      "year": 2018
     },
     "note": "bibtex:blSolving",
     "publisher": "CEPR Discussion Papers",
     "title": "Solving heterogeneous agent models in discrete time with many idiosyncratic states by perturbation methods",
     "type": "report"
    },
    "6202365/L5GBWHBM": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "6202365/L5GBWHBM",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    },
    "undefined": {
     "author": [
      {
       "family": "Reiter",
       "given": "Michael"
      }
     ],
     "container-title": "Journal of Economic Dynamics and Control",
     "id": "6202365/L5GBWHBM",
     "issue": "1",
     "issued": {
      "month": 1,
      "year": 2010
     },
     "note": "Citation Key: reiterBackward",
     "page": "28-35",
     "page-first": "28",
     "title": "Solving the Incomplete Markets Model with Aggregate Uncertainty by Backward Induction",
     "type": "article-journal",
     "volume": "34"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
